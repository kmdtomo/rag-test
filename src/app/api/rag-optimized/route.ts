import { NextRequest, NextResponse } from 'next/server';
import { BedrockAgentRuntimeClient, RetrieveCommand } from '@aws-sdk/client-bedrock-agent-runtime';
import { BedrockRuntimeClient, InvokeModelCommand } from '@aws-sdk/client-bedrock-runtime';

// Knowledge Baseç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
const agentClient = new BedrockAgentRuntimeClient({
  region: process.env.AWS_REGION,
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
});

// Bedrock Runtimeç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
const bedrockClient = new BedrockRuntimeClient({
  region: process.env.AWS_REGION,
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
});

// æ¤œç´¢æˆ¦ç•¥ã‚’è€ƒæ…®ã—ãŸæ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
function createOptimizedPrompt(
  originalQuery: string,
  results: any[],
  searchQueries: string[]
): string {
  const searchResults = results.map((result, index) => {
    const score = result.adjustedScore || result.score || 0;
    return `[${index + 1}] ã‚¹ã‚³ã‚¢: ${score.toFixed(3)}\n${result.content?.text || ''}\n---`;
  }).join('\n\n');

  return `
ã‚ãªãŸã¯é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

æ¤œç´¢æˆ¦ç•¥:
${searchQueries.map((q, i) => `${i + 1}. ${q}`).join('\n')}

æ¤œç´¢çµæœï¼ˆé–¢é€£åº¦é †ï¼‰:
${searchResults}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: ${originalQuery}

æŒ‡ç¤º:
1. ä¸Šè¨˜ã®æ¤œç´¢çµæœã®ã¿ã‚’ä½¿ç”¨ã—ã¦å›ç­”
2. å„æƒ…å ±ã«ã¯ [${'ç•ªå·'}] ã§å¼•ç”¨ã‚’ä»˜ã‘ã‚‹
3. ç•°ãªã‚‹è¦³ç‚¹ã‹ã‚‰ã®æƒ…å ±ã‚’çµ±åˆ
4. Markdownå½¢å¼ã§æ§‹é€ åŒ–
5. æ—¥æœ¬èªã§å›ç­”

å›ç­”:`;
}

// ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¯ã‚¨ãƒªåˆ†è§£ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
const INTELLIGENT_QUERY_DECOMPOSITION_PROMPT = `è³ªå•ã‚’åˆ†æã—ã€Knowledge Baseæ¤œç´¢ã«æœ€é©ãª3ã¤ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
1. å˜èªã§ã¯ãªãã€å®Œå…¨ãªæ–‡ã‚„æ„å‘³ã®ã‚ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚ºã§
2. å„ã‚¯ã‚¨ãƒªã¯ç•°ãªã‚‹è¦³ç‚¹ã‹ã‚‰ï¼ˆæ¦‚å¿µ/å®Ÿè£…/å¿œç”¨ãªã©ï¼‰
3. å…ƒã®è³ªå•ã®æ„å›³ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒ
4. å°‚é–€ç”¨èªã¯ãã®ã¾ã¾ä¿æŒ

è³ªå•: {question}

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
[
  {"query": "æ¦‚å¿µçš„ãªè¦³ç‚¹ã‹ã‚‰ã®æ¤œç´¢æ–‡", "weight": 1.0},
  {"query": "å®Ÿè£…è¦³ç‚¹ã‹ã‚‰ã®æ¤œç´¢æ–‡", "weight": 0.8},
  {"query": "å¿œç”¨ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹è¦³ç‚¹", "weight": 0.6}
]`;

interface RetrievalConfig {
  numberOfResults?: number;
  searchType?: 'HYBRID' | 'SEMANTIC';
  overrideSearchType?: 'SEMANTIC' | 'HYBRID';
}

interface EnhancedQuery {
  query: string;
  weight: number;
}

// ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¯ã‚¨ãƒªåˆ†è§£é–¢æ•°
async function decomposeQueryIntelligently(question: string): Promise<EnhancedQuery[]> {
  try {
    console.log('\nğŸ” Decomposing query intelligently...');
    const prompt = INTELLIGENT_QUERY_DECOMPOSITION_PROMPT.replace('{question}', question);
    
    const command = new InvokeModelCommand({
      modelId: 'anthropic.claude-3-haiku-20240307-v1:0',
      body: JSON.stringify({
        anthropic_version: "bedrock-2023-05-31",
        max_tokens: 512,
        temperature: 0,
        messages: [{
          role: "user",
          content: prompt
        }]
      })
    });

    const response = await bedrockClient.send(command);
    const responseBody = JSON.parse(new TextDecoder().decode(response.body));
    const queries = JSON.parse(responseBody.content[0].text);
    
    console.log('Generated enhanced queries:');
    queries.forEach((q: EnhancedQuery, i: number) => {
      console.log(`  ${i + 1}. [Weight: ${q.weight}] ${q.query}`);
    });
    
    return queries;
  } catch (error) {
    console.error('âŒ Query decomposition failed:', error);
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®è³ªå•ã‚’ãã®ã¾ã¾ä½¿ç”¨
    return [{ query: question, weight: 1.0 }];
  }
}

// AWSã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã—ï¼‰
function sortByAWSScore(results: any[]): any[] {
  return results.sort((a, b) => (b.score || 0) - (a.score || 0));
}

// ã‚¹ãƒãƒ¼ãƒˆãªé‡è¤‡é™¤å»
function smartDeduplication(results: any[]): any[] {
  const uniqueResults: any[] = [];
  const seenContent = new Map<string, any>();
  
  for (const result of results) {
    // ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰
    const contentText = result.content?.text || '';
    const contentHash = Buffer.from(contentText.substring(0, 200)).toString('base64');
    
    // æ—¢ã«è¦‹ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ãƒã‚§ãƒƒã‚¯
    if (seenContent.has(contentHash)) {
      const existing = seenContent.get(contentHash);
      // ã‚ˆã‚Šé«˜ã„ã‚¹ã‚³ã‚¢ã®æ–¹ã‚’ä¿æŒ
      if (result.score > existing.score) {
        const index = uniqueResults.indexOf(existing);
        uniqueResults[index] = result;
        seenContent.set(contentHash, result);
      }
      continue;
    }
    
    // æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦è¿½åŠ 
    uniqueResults.push(result);
    seenContent.set(contentHash, result);
  }
  
  return uniqueResults;
}

// ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã—ãŸæœ€é©åŒ–æ¤œç´¢
async function performOptimizedRetrieval(
  query: string,
  originalQuestion: string,  // å…ƒã®è³ªå•ã‚’ä¿æŒ
  config: RetrievalConfig = {}
): Promise<any[]> {
  const {
    numberOfResults = 10,
    searchType = 'HYBRID',
    overrideSearchType
  } = config;

  // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã—ãŸã‚¯ã‚¨ãƒª
  const contextualQuery = `${query} (ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: ${originalQuestion})`;
  
  console.log(`  ğŸ” Searching with: "${query}"`);
  console.log(`     Config: ${numberOfResults} results, ${searchType} search`);

  const retrieveCommand = new RetrieveCommand({
    knowledgeBaseId: process.env.BEDROCK_KNOWLEDGE_BASE_ID!,
    retrievalQuery: {
      text: contextualQuery
    },
    retrievalConfiguration: {
      vectorSearchConfiguration: {
        numberOfResults,
        overrideSearchType: overrideSearchType || searchType as any
      }
    }
  });

  const response = await agentClient.send(retrieveCommand);
  const results = response.retrievalResults || [];
  console.log(`     âœ“ Retrieved ${results.length} results`);
  
  return results;
}

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  const stepTimings: { [key: string]: number } = {};
  
  const logStep = (step: string) => {
    const currentTime = Date.now();
    const elapsed = currentTime - startTime;
    stepTimings[step] = elapsed;
    console.log(`[${elapsed}ms] ${step}`);
  };
  
  try {
    logStep('Request received');
    const { message, model, enableOptimizations = true } = await request.json();

    if (!message) {
      return NextResponse.json(
        { error: true, message: 'No message provided' },
        { status: 400 }
      );
    }

    console.log('\n========================================');
    console.log('=== RAG Optimized API Request ===');
    console.log('========================================');
    console.log('Query:', message);
    console.log('Model:', model);
    console.log('Optimizations enabled:', enableOptimizations);
    console.log('Knowledge Base ID:', process.env.BEDROCK_KNOWLEDGE_BASE_ID);
    console.log('AWS Region:', process.env.AWS_REGION);
    console.log('========================================\n');
    
    logStep('Initial setup completed');

    let allResults: any[] = [];
    let searchQueries: string[] = [];

    if (enableOptimizations) {
      // Step 1: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¯ã‚¨ãƒªåˆ†è§£
      console.log('\nğŸ” Step 1: Intelligent Query Decomposition');
      console.log('â”€'.repeat(50));
      logStep('Starting intelligent query decomposition');
      const enhancedQueries = await decomposeQueryIntelligently(message);
      logStep('Query decomposition completed');
      searchQueries = enhancedQueries.map(eq => eq.query);

      // Step 2: ä¸¦åˆ—æ¤œç´¢ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒï¼‰
      console.log('\nğŸ”„ Step 2: Parallel Retrieval with Context');
      console.log('â”€'.repeat(50));
      logStep('Starting parallel retrieval');
      
      const searchPromises = enhancedQueries.map((eq, index) => 
        performOptimizedRetrieval(
          eq.query,
          message,  // å…ƒã®è³ªå•ã‚’æ¸¡ã™
          {
            numberOfResults: Math.max(5, 10 - index * 2), // å¾´ã€…ã«æ¸›ã‚‰ã™
            searchType: index === 0 ? 'SEMANTIC' : 'HYBRID'
          }
        )
      );
      
      console.log('\nğŸš€ Executing parallel searches...');
      const searchResults = await Promise.all(searchPromises);
      
      // çµæœã®çµ±åˆï¼ˆé‡ã¿ä»˜ã‘ï¼‰
      searchResults.forEach((results, queryIndex) => {
        const weight = enhancedQueries[queryIndex].weight || 1.0;
        console.log(`\n  Query ${queryIndex + 1} results: ${results.length} items (weight: ${weight})`);
        results.forEach((result: any) => {
          allResults.push({
            ...result,
            adjustedScore: (result.score || 0) * weight,
            originalScore: result.score,
            queryIndex: queryIndex + 1
          });
        });
      });
      
      logStep('All retrievals completed');
      console.log(`\n  âœ“ Total results collected: ${allResults.length}`);

      // Step 3: ã‚¹ãƒãƒ¼ãƒˆãªé‡è¤‡é™¤å»
      console.log('\nğŸ§ª Step 3: Smart Deduplication');
      console.log('â”€'.repeat(50));
      logStep('Starting smart deduplication');
      const beforeDedup = allResults.length;
      
      allResults = smartDeduplication(allResults);
      
      console.log(`\n  ğŸ“Š Deduplication results:`);
      console.log(`     Before: ${beforeDedup} results`);
      console.log(`     After: ${allResults.length} results`);
      console.log(`     Removed: ${beforeDedup - allResults.length} duplicates (${((beforeDedup - allResults.length) / beforeDedup * 100).toFixed(1)}%)`);
      logStep('Deduplication completed');

      // Step 4: AWSã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã—ï¼ï¼‰
      console.log('\nğŸ† Step 4: Sorting by AWS Scores (No Re-ranking!)');
      console.log('â”€'.repeat(50));
      logStep('Starting AWS score-based sorting');
      
      // èª¿æ•´ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
      allResults.sort((a, b) => (b.adjustedScore || 0) - (a.adjustedScore || 0));
      
      // ä¸Šä½15ä»¶ã‚’é¸æŠ
      const beforeTrim = allResults.length;
      allResults = allResults.slice(0, 15);
      console.log(`\n  âœ‚ï¸ Trimmed to top ${allResults.length} results (from ${beforeTrim})`);
      
      // ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚’è¡¨ç¤º
      console.log('\n  ğŸ“Š Score distribution:');
      const scoreRanges = {
        high: allResults.filter(r => r.adjustedScore > 0.8).length,
        medium: allResults.filter(r => r.adjustedScore > 0.5 && r.adjustedScore <= 0.8).length,
        low: allResults.filter(r => r.adjustedScore <= 0.5).length
      };
      console.log(`     High (>0.8): ${scoreRanges.high} results`);
      console.log(`     Medium (0.5-0.8): ${scoreRanges.medium} results`);
      console.log(`     Low (<=0.5): ${scoreRanges.low} results`);
      
      logStep('Sorting completed');
    } else {
      // æœ€é©åŒ–ãªã—ã®é€šå¸¸æ¤œç´¢
      console.log('\n--- Standard Retrieval (No Optimization) ---');
      logStep('Starting standard retrieval');
      searchQueries = [message];
      allResults = await performOptimizedRetrieval(message, message, {
        numberOfResults: 10,
        searchType: 'SEMANTIC'
      });
      logStep(`Standard retrieval completed: ${allResults.length} results`);
    }

    // ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
    console.log('\nğŸ“„ Final Search Results');
    console.log('â”€'.repeat(50));
    allResults.forEach((result, index) => {
      console.log(`\nğŸ”– Result ${index + 1}:`);
      console.log(`   Original Score: ${result.originalScore?.toFixed(4) || result.score?.toFixed(4) || 'N/A'}`);
      if (result.adjustedScore !== undefined) {
        console.log(`   Adjusted Score: ${result.adjustedScore.toFixed(4)} (Query #${result.queryIndex || 'N/A'})`);
      }
      console.log(`   URI: ${result.location?.s3Location?.uri || 'N/A'}`);
      console.log(`   Content: ${result.content?.text?.substring(0, 100).replace(/\n/g, ' ')}...`);
    });
    logStep('Search results analysis completed');

    // Step 5: æ¤œç´¢çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    console.log('\nğŸ“ Step 5: Formatting Results for Generation');
    console.log('â”€'.repeat(50));
    const searchResults = allResults.map((result, index) => {
      const score = result.adjustedScore || result.score || 0;
      return `[${index + 1}] (Score: ${score.toFixed(3)}) ${result.content?.text || ''}`;
    }).join('\n\n');
    console.log(`  âœ“ Formatted ${allResults.length} results for generation`);

    // Step 6: æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    const finalPrompt = createOptimizedPrompt(message, allResults, searchQueries);

    // Step 7: Claude ã«ç”Ÿæˆã‚’ä¾é ¼
    const modelMap = {
      'sonnet35': process.env.BEDROCK_MODEL_ID_SONNET_35 || 'apac.anthropic.claude-3-5-sonnet-20241022-v2:0',
      'sonnet4': process.env.BEDROCK_MODEL_ID_SONNET_4 || 'apac.anthropic.claude-sonnet-4-20250514-v1:0'
    };
    const modelId = modelMap[model as keyof typeof modelMap] || modelMap['sonnet35'];
    
    const generateCommand = new InvokeModelCommand({
      modelId: modelId,
      body: JSON.stringify({
        anthropic_version: "bedrock-2023-05-31",
        max_tokens: 4096,
        temperature: 0.1,
        top_p: 0.95,
        messages: [{
          role: "user",
          content: finalPrompt
        }]
      })
    });

    console.log('\nğŸ¤– Step 7: Response Generation');
    console.log('â”€'.repeat(50));
    logStep('Starting response generation');
    console.log(`  ğŸ¯ Using model: ${modelId}`);
    const generateResponse = await bedrockClient.send(generateCommand);
    logStep('Response generation completed');
    const responseBody = JSON.parse(new TextDecoder().decode(generateResponse.body));
    console.log(`  âœ“ Generated response: ${responseBody.content?.[0]?.text?.length || 0} characters`);
    
    logStep('Response preparation completed');
    
    const totalTime = Date.now() - startTime;
    console.log('\n========================================');
    console.log('=== RAG Optimized API Response Summary ===');
    console.log('========================================');
    console.log(`Total response time: ${totalTime}ms (${(totalTime / 1000).toFixed(2)}s)`);
    console.log('\nStep timings:');
    Object.entries(stepTimings).forEach(([step, time]) => {
      console.log(`  - ${step}: ${time}ms`);
    });
    console.log(`\nOptimizations applied: ${enableOptimizations ? 'Yes' : 'No'}`);
    if (enableOptimizations) {
      console.log(`Sub-queries generated: ${searchQueries.length}`);
      searchQueries.forEach((sq, idx) => {
        console.log(`  ${idx + 1}. ${sq}`);
      });
    }
    console.log(`Final sources: ${allResults.length}`);
    console.log(`Response length: ${responseBody.content?.[0]?.text?.length || 0} characters`);
    console.log(`Model used: ${model}`);
    console.log('========================================\n');
    
    return NextResponse.json({
      response: responseBody.content?.[0]?.text || 'No response generated',
      sources: allResults.map(result => ({
        content: result.content?.text,
        location: result.location,
        uri: result.location?.s3Location?.uri,
        score: result.score
      })),
      metadata: {
        searchQueries,
        totalResults: allResults.length,
        optimizationsApplied: enableOptimizations ? [
          'intelligent_query_decomposition',
          'contextual_search',
          'smart_deduplication',
          'aws_native_scoring'  // å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã—ï¼
        ] : ['semantic_search']
      }
    });

  } catch (error: any) {
    console.error('RAG Optimized API error:', error);

    const isRateLimit = error.name === 'ThrottlingException' || 
                       error.name === 'ServiceQuotaExceededException' ||
                       error.$metadata?.httpStatusCode === 429;
    
    return NextResponse.json(
      { 
        error: true, 
        message: error.message || 'Optimized chat processing failed', 
        code: error.name || 'OPTIMIZED_CHAT_ERROR',
        isRateLimit: isRateLimit,
        userMessage: isRateLimit ? 
          'ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã¾ã™ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚' : 
          'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
        details: error.$metadata
      },
      { status: isRateLimit ? 429 : 500 }
    );
  }
}